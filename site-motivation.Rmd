---
title: "Motivation & Goals"
author: ""
date: "12/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(haven)
```


# Predicting Capital Bikes Departures


```{r setup2, include=FALSE}
knitr::include_graphics("map.png")
```


DC's Capital Bikeshare service has been increasing in popularity, especially during the COVID-19 pandemic, when Washingtonians needed alternatives for public transport. To date it has 5,000 bikes and 600+ stations across 7 jurisdictions. However, users find the service unreliable at times, especially at peak times. In this project, our goal is to use and optimize supervised machine learning models that can predict the number of ride-sharing bikes that will be used at any give hour. For simplicity, we apply our models to one station in particular that has particularly high demand due to its proximity to DC's greatest tourist attraction: the Lincoln Memorial station. As such, our target variable will be the number of bikes that departed from that station at a given hour.

We chose predictors that vary by the hour that we believe are relevant to individuals' choices of taking a capital Bikeshare bike. They are of three types:

* weather: this includes general weather conditions (categorical variable), rain, temperature, snow. 
* sunlight: this is a dummy variable for whether there is sunlight or not
* time: this includes day of the week, weekday, month, year, as well as selected holiday days.
* other stations: this includes departures from stations in an [ADD] mile radius


Being able to predict Capital Bikeshare demand, could result in a more efficient allocation of bikes when stations are re-stocked at night. It could also inform and it could inform the eventual expansion of stations across strategic locations across the city to improve the experience of Washingtonians.

# Data

We use Capital Bikeshare's publicly available [historic data](https://www.capitalbikeshare.com/system-data), ranging from May 2020 until September 2021. After data cleaning, our dataset has 309197 rows (CONFIRM?), each indicating the number of hours that departed Lincoln Memorial at a certain hour.

For weather predictors we used data from ADD

For sunlight we used data from ADD


# Overall method

here is where we explain why we used certain algorithms versus others - I thinkw e are using parametric algorithm because we have a very wide dataset?

We start with a simple decision tree. Then random forest with hyperparameter tuning.


### Error Metric 

We will use RMSE as our error metric to judge how well our models do. RMSE is very sensitive to outlines as it squares them resulting in a bigger error. From the exploration done above, I would expect a large RMSE as the range within and across days in terms of hourly departures is wide regardless of the hour. How much error is too much depends on how loose or strict we want to predict our outcomes. For our project, some error is probably accepted but being too loose in deciding what the error would be might cost the company money and decrease efficiency because they might be overprovidng or underproviding bikes at their stations. Based on the average departures per hour on any given day *insert number* , I think an RMSE of 2-3 would be acceptable


