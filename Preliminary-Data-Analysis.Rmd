---
title: "Data analysis"
author: "Elena Bagnera"
date: "11/13/2021"
output: html_document
---

```{r include = FALSE}
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::opts_chunk$set(cache = FALSE)
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
  }
)
# knitr::knit_hooks$set(inline = function(x) {
#   prettyNum(round(x, 2), big.mark = ",")
# })
options(scipen=999)
```


\begin{center}
\Huge{PPOL 670 | Final Project}

\Huge{Capital Bikeshare}
\end{center}

\vspace{0.1in}

[GitHub](https://github.com/elenabagnera/CapitalBikesProject)

## Setup
```{r setup, message=FALSE}
library(tidyverse)
library(tidymodels)
library(recipes)
library(vip)
library(lubridate)
library(workflows)
library(ranger)
doParallel::registerDoParallel()
```


[Direct link to dataset](https://s3.amazonaws.com/capitalbikeshare-data/202108-capitalbikeshare-tripdata.zip)

```{r, cache=TRUE, warning=FALSE, message=FALSE}
source("times.R")

## Loop through all the files and merge them into one tibble
file_list <- list.files("data/", pattern="tripdata.csv")
rm(cbs_data)

for(file_name in file_list) {
  path <- paste("data/", file_name, sep="")

  new_data <- read_csv(path)
  
  if (exists("cbs_data")){
    cbs_data <- bind_rows(cbs_data, new_data)
  } else {
    cbs_data <- new_data
  }
}

data <- cbs_data %>% 
  pivot_longer(c("started_at", "ended_at"), names_to="time_type", values_to="time") %>% 
  mutate(station = ifelse(time_type == "started_at", start_station_name, end_station_name)) %>% 
  select(-start_station_name, -end_station_name)

# Add a column for multiple time metrics
# Then group rows to show total arrivals and departure per hour
# Then pivot the table wider so that each hour has its own row with every station on it
# Then remove all NAs and replace with zero.
# Made them all lowercase and used underscores, the number of spaces could get confusing
# I tried making them all valid variable names, but it created duplicates.
hour_data <- mutate_times(data) %>% 
  # If you only want certain stations data, filter here
  group_by(year, month, day, hour, station, time_type) %>% 
  summarize(count = n()) %>% 
  pivot_wider(names_from="station", values_from = "count") %>% 
  mutate(type = ifelse(time_type == "started_at", "departures", "arrivals")) %>% 
  select(-time_type) %>% 
  mutate_all(~ifelse(is.na(.), 0, .)) %>% 
  rename_with(~ tolower(str_replace_all(., pattern = " ", replacement = "_")))

# Create a new field called ridership that will be the actual riders on the 
# Lincoln memorial stop
ridership_data <- hour_data %>% 
  mutate(ridership = NA)
```


```{r create_ridership, cache=TRUE}
# This loop gets the values from the Lincoln memorial and puts it into the ridership
# ridership column 14 days into the future. The goal is to couple lincoln memorial rides
# with every station from 14 days ago for predictions.
# When this is done running, the dates now represent future ridership, we need to shift
# them 14 days into the future, so all the stations will be 14 day historic data.
for (year in 2020:2021) {
  for (month in month.abb) {
    for (day in 1:31) {
      for (hour in 0:23) {
        dep_index_prev <- which(hour_data$year == year &
          hour_data$month == month &
          hour_data$day == day &
          hour_data$hour == hour &
          hour_data$type == "departures")

        if (length(dep_index_prev) > 0) {
          future_time <- make_datetime(year, match(month, month.abb), day, hour) + days(14)
          dep_index_future <- which(hour_data$year == year(future_time) &
            hour_data$month == (month.abb[month(future_time)]) &
            hour_data$day == day(future_time) &
            hour_data$hour == hour(future_time) &
            hour_data$type == "departures")
          if (length(dep_index_future) > 0) {
            # Get future ridership and pair it with 14 day ago rides.
            ridership_data$ridership[dep_index_prev] <- ridership_data$lincoln_memorial[dep_index_future]
          }
        }

        arr_index_prev <- which(hour_data$year == year &
          hour_data$month == month &
          hour_data$day == day &
          hour_data$hour == hour &
          hour_data$type == "arrivals")

        if (length(arr_index_prev) > 0) {
          future_time <- make_datetime(year, match(month, month.abb), day, hour) + days(14)
          arr_index_future <- which(hour_data$year == year(future_time) &
            hour_data$month == (month.abb[month(future_time)]) &
            hour_data$day == day(future_time) &
            hour_data$hour == hour(future_time) &
            hour_data$type == "arrivals")
          
          if (length(arr_index_future) > 0) {
            ridership_data$ridership[arr_index_prev] <- ridership_data$lincoln_memorial[arr_index_future]
          }
        }
      }
    }
  }
}

# Shift the dates 14 days into the future
# I tried to do this with a map function, but ran into issues.
for (index in 1:nrow(ridership_data)) {
  date <- make_datetime(ridership_data$year[index], 
                        match(ridership_data$month[index], month.abb), 
                        ridership_data$day[index])
  
  future_date <- date + days(14)

  ridership_data$year[index] = year(future_date)
  ridership_data$month[index] = month.abb[month(future_date)]
  ridership_data$day[index] = day(future_date)
}

write_csv(ridership_data, 'data/ridership.csv')
```


```{r test_ridership}
# Just testing one data point, should probably test this is working as intended more
# ridership_data's lincoln_memorial column should match the hour_data's 
#  lincoln memorial from 14 days prior.
# Ridership_data's ridership should match hour_data's lincoln memorial from the same date.
hour_data %>% 
  select(lincoln_memorial, year, month, day, hour) %>% 
  filter(year == 2021, month == "Jul", day == 3, hour == 12)
  
hour_data %>% 
  select(lincoln_memorial, year, month, day, hour, type) %>% 
  filter(year == 2021, month == "Jul", day == 17, hour == 12)
  
ridership_data %>% 
  select(ridership, lincoln_memorial, year, month, day, hour, type) %>% 
  filter(year == 2021, month == "Jul", day == 17, hour == 12)

```

## Visualizations and Explorations

Amount of rides at the lincoln memorial over all the time, and by various metrics

```{r}

hour_data_date <- hour_data %>% 
  mutate(date = make_datetime(year,match(month, month.abb),day,hour))

hour_data_date %>% 
  ggplot() +
  geom_point(aes(x=date, y=lincoln_memorial, color=type))

hour_data_date %>% 
  mutate(weekday = wday(date, label=TRUE)) %>% 
  ggplot() +
  geom_point(aes(x=weekday, y=lincoln_memorial, color=type))

hour_data_date %>% 
  ggplot() +
  geom_point(aes(x=day, y=lincoln_memorial, color=type))

hour_data_date %>% 
  ggplot() +
  geom_point(aes(x=hour, y=lincoln_memorial, color=type))

hour_data_date %>% 
  filter(year == 2021, month == "Aug", day == 15) %>% 
  ggplot() +
  geom_line(aes(x=hour, y=lincoln_memorial, color=type))
```

## Implementation

```{r}
l_ridership_data <- ridership_data %>% 
  mutate(date = make_datetime(year,match(month, month.abb),day,hour)) %>% 
  mutate(weekday = wday(date, label=TRUE)) %>% 
  filter(type == "departures", !is.na(ridership)) %>% 
  select(-type)

# create a split object
l_data_split <- initial_split(l_ridership_data, prop = 0.8)

# create the training and testing data
l_train <- training(x = l_data_split)
l_test  <- testing(x = l_data_split)

folds <- vfold_cv(data = l_train, v = 10)

l_recipe <-
  recipe(formula = ridership ~ ., data = l_train) %>%
  step_dummy(all_nominal_predictors()) %>% 
  #step_center(all_numeric_predictors()) %>%
  step_holiday(date, holidays = timeDate::listHolidays("US"))
```


```{r l_tuning, cache=TRUE}
l_mod <- rand_forest(mtry = tune(), trees = 500, min_n = tune()) %>%
  set_mode("regression") %>%
  set_engine("ranger")

l_wf <- workflow() %>%
  add_recipe(l_recipe) %>%
  add_model(l_mod) 

l_tune_results <- tune_grid(
  l_wf,
  resamples = folds,
  grid = 20,
  metrics = metric_set(rmse, mae)
)

l_metrics <- l_tune_results %>%
  collect_metrics() %>% 
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  )
```

#### Results to better tune the mtry and min_n

```{r l_graphs}
l_metrics %>%  
  filter(.metric == "rmse") %>% 
  ggplot(aes(x = value, y = mean, color = parameter)) + 
  geom_point() + 
  labs(title = "RMSE")

l_metrics %>%  
  filter(.metric == "mae") %>% 
  ggplot(aes(x = value, y = mean, color = parameter)) + 
  geom_point() +
  labs(title = "MAE")
```

Pick the results.

```{r l_ft_results}
l_best_rmse <- l_tune_results %>% 
  select_best("rmse")

l_best_rmse

l_best_mae <-l_tune_results %>% 
  select_best("mae")

l_best_mae

l_final_rf <- finalize_model(
  l_mod,
  l_best_rmse
)

collect_metrics(l_tune_results, summarize = FALSE) %>%
  filter(.metric == "rmse" || .metric == "mae") %>%
  ggplot(aes(x = id, y = .estimate, group = .estimator)) +
  geom_point(aes(color=.metric)) +
  scale_y_continuous(limits = c(0, 5)) +
  labs(title = "Calculated MAE and RMSE Across the 10 Folds",
     y = "RMSE_hat") +
  theme_minimal()

collect_metrics(l_tune_results, summarize = FALSE) %>%
  filter(.metric == "rmse") %>%
  summarize(mean(.estimate))
```

```{r chosen_one}
l_final_wf <- workflow() %>%
  add_recipe(l_recipe) %>%
  add_model(l_final_rf) %>% 
  fit(l_train)

l_p_test <- bind_cols(
  l_test,
  predict(object = l_final_wf, new_data = l_test))
```

Out of sample RMSE
```{r OOS_RMSE_lincoln}
sqrt(mean((l_p_test$ridership - l_p_test$.pred)^2))
```

```{r lincoln_final_vip, warning=FALSE}
l_final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(ridership ~ .,
    data = l_train
  ) %>%
  vip(geom = "point")
```