---
title: "Motivation & Goals"
author: "Elena Bagnera"
date: "12/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(haven)
```


## Predicting Capital Bikes Departures


could be nice to have a pic at the start
```{r setup2}
knitr::include_graphics("map.png")
```


DC's Capital Bikeshare service has been increasing in popularity, especially during the COVID-19 pandemic, when Washingtonians needed alternatives for public transport. To date it has 5,000 bikes and 600+ stations across 7 jurisdictions. However, users find the service unreliable at times, especially at peak times. In this project, our goal is to use and optimize supervised machine learning models that can predict the number of ride-sharing bikes that will be used at any give hour. For simplicity, we apply our models to one station in particular that has particularly high demand due to its proximity to DC's greatest tourist attraction: the Lincoln Memorial station. As such, our target variable will be the number of bikes that departed from that station at a given hour.

We chose predictors that vary by the hour that we believe are relevant to individuals' choices of taking a capital Bikeshare bike. They are of three types:

* weather: this includes general weather conditions (categorical variable), rain, temperature, snow. 
* sunlight: this is a dummy variable for whether there is sunlight or not
* time: this includes day of the week, weekday, month, year, as well as selected holiday days.
* other stations: this includes departures from stations in an [ADD] mile radius


Being able to predict Capital Bikeshare demand, could result in a more efficient allocation of bikes when stations are re-stocked at night. It could also inform and it could inform the eventual expansion of stations across strategic locations across the city to improve the experience of Washingtonians.

## Data

We use Capital Bikeshare's publicly available [historic data](https://www.capitalbikeshare.com/system-data), ranging from May 2020 until September 2021. After data cleaning, our dataset has 309197 rows (CONFIRM?), each indicating the number of hours that departed Lincoln Memorial at a certain hour.

For weather predictors we used data from ADD

For sunlight we used data from ADD

## Overall method

here is where we explain why we used certain algorithms versus others - I thinkw e are using parametric algorithm because we have a very wide dataset?

We start with a simple decision tree. Then random forest with hyperparameter tuning.


