---
title: "random_forest"
author: "Elena Bagnera"
date: "11/13/2021"
output: html_document
---

```{r include = FALSE}
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::opts_chunk$set(cache = FALSE)
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
  }
)
# knitr::knit_hooks$set(inline = function(x) {
#   prettyNum(round(x, 2), big.mark = ",")
# })
options(scipen=999)
```


\begin{center}
\Huge{PPOL 670 | Final Project}

\Huge{Random Forest}
\end{center}

\vspace{0.1in}

[GitHub](https://github.com/elenabagnera/CapitalBikesProject)

## Setup
```{r setup, message=FALSE}
library(tidyverse)
library(tidymodels)
library(recipes)
library(vip)
library(lubridate)
library(workflows)
library(ranger)
source("times.R")
source("io.R")
source("manipulate_data.R")
doParallel::registerDoParallel()
```

[Direct link to dataset](https://s3.amazonaws.com/capitalbikeshare-data/202108-capitalbikeshare-tripdata.zip)

```{r get_data, cache=TRUE, warning=FALSE, message=FALSE}

cbs_data <- read_files('data/')
data <- sep_departures_from_arrivals(cbs_data) %>% 
  filter(!is.na(station)) # Remove electric bikes not going to / from a station

filtered_data <- filter_by_distance(data, from_station = 'lincoln_memorial', distance_m = 5000)

hour_data <- get_station_hourly(filtered_data) %>% 
  get_historic_weather()

lagged_data <- setup_for_time_prediction(hour_data, station_name = "lincoln_memorial")
```

## Implementation

```{r setup_data}

set.seed(28021995)

model_data <- lagged_data %>% 
  add_predictor_times() %>% 
  filter(!is.na(departures) & !is.na(arrivals)) %>% 
  # Having real time arrival data would be cheating
  select(-arrivals, -wind_chill, -heat_index, -wind_direction, -wind_gust)

# create a split object
data_split <- initial_split(model_data, prop = 0.8)

# create the training and testing data
train <- training(x = data_split)
test  <- testing(x = data_split)

folds <- vfold_cv(data = train, v = 10)

recipe <-
  recipe(formula = departures ~ ., data = train) %>%
  step_dummy(all_nominal_predictors()) %>% # note: apparently aaron said that this won't affect random forest
  step_center(all_numeric_predictors()) %>% # note: apparently aaron said that this won't affect random forest
  step_holiday(date, holidays = timeDate::listHolidays("US")) %>% # aaron said we should put more weight on some holidays rather than other, for example 4th of july and inauguration day especially since we are looking at lincoln memorial
  step_nzv() %>% # aaron suggested adding this
  step_other() # add this for any categorical predictors
  
  #notice that we also need to add some transformation of the dependent variable

```


```{r tuning, cache=TRUE}
mod <- rand_forest(mtry = tune(), trees = 200, min_n = tune()) %>% # we should have anywhere between 100 and 1000 trees
  set_mode("regression") %>%
  set_engine("ranger")

wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(mod) 

tune_results <- tune_grid(
  wf,
  resamples = folds,
  grid = 10,
  metrics = metric_set(rmse, mae)
)

metrics <- tune_results %>%
  collect_metrics() %>% 
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  )
```

#### Results to better tune the mtry and min_n

```{r graphs}
metrics %>%  
  filter(.metric == "rmse") %>% 
  ggplot(aes(x = value, y = mean, color = parameter)) + 
  geom_point() + 
  labs(title = "RMSE")

metrics %>%  
  filter(.metric == "mae") %>% 
  ggplot(aes(x = value, y = mean, color = parameter)) + 
  geom_point() +
  labs(title = "MAE")
```

Pick the results.

```{r ft_results}
best_rmse <- tune_results %>% 
  select_best("rmse")

best_rmse

best_mae <-tune_results %>% 
  select_best("mae")

best_mae

final_rf <- finalize_model(
  mod,
  best_rmse
)

collect_metrics(tune_results, summarize = FALSE) %>%
  filter(.metric == "rmse" || .metric == "mae") %>%
  ggplot(aes(x = id, y = .estimate, group = .estimator)) +
  geom_point(aes(color=.metric)) +
  scale_y_continuous(limits = c(0, 5)) +
  labs(title = "Calculated MAE and RMSE Across the 10 Folds",
     y = "RMSE_hat") +
  theme_minimal()

collect_metrics(tune_results, summarize = FALSE) %>%
  filter(.metric == "rmse") %>%
  summarize(mean(.estimate))
```

```{r chosen_one}
final_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(final_rf) %>% 
  fit(train)

p_test <- bind_cols(
  test,
  predict(object = final_wf, new_data = test))
```

Out of sample RMSE
```{r OOS_RMSE_lincoln}
sqrt(mean((p_test$departures - p_test$.pred)^2))
```

```{r lincoln_final_vip, warning=FALSE}
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(departures ~ .,
    data = train
  ) %>%
  vip(geom = "point")
```