---
title: "random_forest"
author: "Elena Bagnera"
date: "11/13/2021"
output: html_document
---

```{r include = FALSE}
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::opts_chunk$set(cache = FALSE)
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
  }
)
# knitr::knit_hooks$set(inline = function(x) {
#   prettyNum(round(x, 2), big.mark = ",")
# })
options(scipen=999)
```

\begin{center}
\Huge{PPOL 670 | Final Project}

\Huge{Random Forest}
\end{center}

\vspace{0.1in}

[GitHub](https://github.com/elenabagnera/CapitalBikesProject)

## Setup

```{r setup, message=FALSE}
library(tidyverse)
library(tidymodels)
library(recipes)
library(vip)
library(lubridate)
library(workflows)
library(ranger)
source("times.R")
source("io.R")
source("manipulate_data.R")
doParallel::registerDoParallel()
```

[Direct link to dataset](https://s3.amazonaws.com/capitalbikeshare-data/202108-capitalbikeshare-tripdata.zip)

```{r get_data, cache=FALSE, warning=FALSE, message=FALSE}
  
cbs_data <- read_files('data/')
data <- sep_departures_from_arrivals(cbs_data) %>%
  filter(!is.na(station)) # Remove electric bikes not going to / from a station

filtered_data <- filter_by_distance(data, from_station = 'lincoln_memorial', distance_m = 1600)

hour_data <- get_station_hourly(filtered_data) %>%
  get_historic_weather() %>% 
  add_sun_is_out()
  #filter(conditions != "Bad") # To test if bad weather really hurts RMSE that much

lagged_data <- setup_for_time_prediction(hour_data, station_name = "lincoln_memorial")
```

## Implementation

```{r setup_data}

set.seed(28021995)

model_data <- lagged_data %>%
  add_predictor_times() %>%
  filter(!is.na(departures) & !is.na(arrivals)) %>%
  # Having real time arrival data would be cheating
  select(-arrivals) %>%
  format_weather()

# create a split object
data_split <- initial_split(model_data, prop = 0.8)

# create the training and testing data
train <- training(x = data_split)
test  <- testing(x = data_split)

folds <- vfold_cv(data = train, v = 10)

recipe <-
  recipe(formula = departures ~ ., data = train) %>%
  step_holiday(date, holidays = timeDate::listHolidays("US"), keep_original_cols = FALSE) %>% # aaron said we should put more weight on some holidays rather than other, for example 4th of july and inauguration day especially since we are looking at lincoln memorial
  step_nzv(all_predictors()) %>% # aaron suggested adding this
  step_other() %>% # add this for any categorical predictors
  step_BoxCox(all_outcomes())  ## only works with positve vars, no problem in our case
  
  
  
  
## this is an example
# step_holiday(
#   recipe,
#   ...,
#   role = "predictor",
#   trained = FALSE,
#   holidays = c("LaborDay", "NewYearsDay", "ChristmasDay"), ## this could be inserted instead of timeDate::listHolidays("US")
#   columns = NULL,
#   keep_original_cols = TRUE,
#   skip = FALSE,
#   id = rand_id("holiday")
# )


## to check what we did!
# holiday_rec <- prep(holiday_rec, training = examples)
# holiday_values <- bake(holiday_rec, new_data = examples)
# holiday_values

# Unlike some other steps, step_holiday does not remove the original date variables by default. Set keep_original_cols to FALSE to remove them.

  #notice that we also need to add some transformation of the dependent variable
```

```{r tuning, cache=TRUE}
# Tuning min_n doesn't seem to help
mod <- rand_forest(mtry = tune(), trees = 200, min_n = tune()) %>% # we should have anywhere between 100 and 1000 trees
  set_mode("regression") %>%
  set_engine("ranger")

wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(mod)

tune_results <- tune_grid(
  wf,
  resamples = folds,
  grid = 8,
  metrics = metric_set(rmse, mae)
)
```

#### Results to better tune the mtry and trees

```{r graphs}
metrics <- tune_results %>%
  collect_metrics() %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  )

metrics %>%
  filter(.metric == "rmse") %>%
  ggplot(aes(x = value, y = mean, color = parameter)) +
  geom_point() +
  labs(title = "RMSE")

metrics %>%
  filter(.metric == "mae") %>%
  ggplot(aes(x = value, y = mean, color = parameter)) +
  geom_point() +
  labs(title = "MAE")

metrics %>%
  filter(.metric == "rmse", parameter == "mtry") %>%
  ggplot(aes(x = value, y = mean)) +
  geom_point() +
  labs(title = "RMSE")

metrics %>%
  filter(.metric == "rmse", parameter == "min_n") %>%
  ggplot(aes(x = value, y = mean)) +
  geom_point() +
  labs(title = "RMSE")
```

Pick the results.

```{r ft_results}
best_rmse <- tune_results %>%
  select_best("rmse")

best_rmse

best_mae <-tune_results %>%
  select_best("mae")

best_mae

final_rf <- finalize_model(
  mod,
  best_rmse
)

collect_metrics(tune_results, summarize = FALSE) %>%
  filter(.metric == "rmse" || .metric == "mae") %>%
  ggplot(aes(x = id, y = .estimate, group = .estimator)) +
  geom_point(aes(color=.metric)) +
  scale_y_continuous(limits = c(0, 5)) +
  labs(title = "Calculated MAE and RMSE Across the 10 Folds",
     y = "RMSE_hat") +
  theme_minimal()

collect_metrics(tune_results, summarize = FALSE) %>%
  filter(.metric == "rmse") %>%
  summarize(mean(.estimate))
```

```{r chosen_one}
final_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(final_rf) %>%
  fit(train)

p_test <- bind_cols(
  test,
  predict(object = final_wf, new_data = test))
```

Out of sample RMSE

```{r OOS_RMSE_lincoln}
sqrt(mean((p_test$departures - p_test$.pred)^2))
```

```{r lincoln_final_vip, warning=FALSE}
final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(departures ~ .,
    data = train
  ) %>%
  vip(geom = "point")
```
