---
title: "visualizations"
author: "Capital Bikes Team"
date: "11/13/2021"
output: html_document
---

```{r include = FALSE}
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::opts_chunk$set(cache = FALSE)
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
  }
)
# knitr::knit_hooks$set(inline = function(x) {
#   prettyNum(round(x, 2), big.mark = ",")
# })
options(scipen = 999)
```

\begin{center}
\Huge{PPOL 670 | Final Project}

\Huge{Visualizations}
\end{center}

\vspace{0.1in}

[GitHub](https://github.com/elenabagnera/CapitalBikesProject)

## Setup
```{r setup, message=FALSE}

library(tidyverse)
library(httr)
library(jsonlite)
source("times.R")
source("io.R")
source("manipulate_data.R")
library(tidymodels)
library(corrplot)
library(suncalc)
library(lubridate)
```


[Direct link to dataset](https://s3.amazonaws.com/capitalbikeshare-data/202108-capitalbikeshare-tripdata.zip)

```{r get real-time data, warning = FALSE, message = FALSE, include = FALSE}

### get real-time data through API
# url <- "https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/Transportation_WebMercator/MapServer/5/query?where=1%3D1&outFields=*&outSR=4326&f=json"

# 1) use the URL to make a request from the API
# data_json <- GET(url = url,
#                  user_agent("Georgetown University Assignment"))
# 2) Check for a server error in the response
# http_status(data_json)
# 3) get the contents of the response as a text string
# data_json <- content(data_json, as = "text")
# 4) create a character matrix from the JSON
# data_matrix <- fromJSON(data_json)
# 5) turn the body of the character matrix into a tibble
# realtime_data <- as_tibble(data_matrix$features$attributes)
# #help needed: how to use lower case for var names?
```

```{r get historical data, warning = FALSE, message = FALSE}

# full-data
cbs_data <- read_files('data/')
data <- sep_departures_from_arrivals(cbs_data) %>%
    filter(!is.na(station)) # Remove electric bikes not going to / from a station

# # partial data
# cbs_data <- read.csv("data/202109-capitalbikeshare-tripdata.csv")
# data <- sep_departures_from_arrivals(cbs_data) %>% 
#   filter(!is.na(station)) # if you want to try first with one data set only to not overload your machine you can use these lines instead of the above

filter_by_distance(data, from_station = 'lincoln_memorial', distance_m = 1600) # added filtering

hour_data <- get_station_hourly(data) %>% 
  get_historic_weather() %>% # added weather
  add_sun_is_out() 

# The grouped data does not have the original date column, but it can be nice for visualizations. There is a function to do this in times.R
hour_data_date <- add_date_column(hour_data)
```

## Splitting the data into training and testing
```{r split}
set.seed(28021995)

# create a split object
data_split <- initial_split(hour_data_date, prop = 0.8)

# create the training and testing data
train_data_date <- training(x = data_split)
test_data_date  <- testing(x = data_split)
```

## Summary stats
```{r stats_dependent}
# summary entire train dataset
summary(train_data_date)

# summary lincoln_memorial_departures
train_data_date %>%
  summarize(
    mean(lincoln_memorial_departures),
    max(lincoln_memorial_departures),
    min(lincoln_memorial_departures),
    sd(lincoln_memorial_departures)) 
# how can we get better summary stats? maybe not split by hour?
```


```{r stats_weather}
# check how much NA in temperature variable
# sum(is.na(train_data_date$temperature)) #0
# sum(is.na(train_data_date$cloud_cover)) #0

train_data_date %>%
 # mutate(weekday = wday(date, label=TRUE)) %>%
  group_by(month) %>%
  summarize(mean(temperature), max(temperature), min(temperature), sd(temperature)) 
```

```{r ride density}

# density plot (no log)
train_data_date %>%
  filter(lincoln_memorial_departures != 0) %>% # notice that we here are dropping 0s
  ggplot(aes(x = lincoln_memorial_departures)) +
  geom_density() +
  labs(title = "xxx", 
       x = "Number of departures from Lincoln Memorial")
# What does the number 50 entail?

# density plot (log)
train_data_date %>%
  filter(lincoln_memorial_departures != 0) %>% # notice that we here are dropping 0s
  ggplot(aes(x = log(lincoln_memorial_departures))) + # add log to fix skewness
  geom_density() +
  labs(title = "xxx", 
       x = "Number of departures from Lincoln Memorial (logged")
# What does the number 4 entail?
```

## Visualizations by time at Lincoln Memorial
In this part, we use Lincoln Memorial as an example to show the change in amount of rides over time, by date, weekday, day of month, hour, 

```{r date}
train_data_date %>%  # for me here there is a weird gap after July 2020, not sure why?
  ggplot(aes(x = date, y = lincoln_memorial_departures)) +
  geom_point(alpha = 0.1, color = "orange") + 
  geom_smooth() +
  labs(title = "",
       x = "Date", 
       y = "The Number of Departures at Lincoln Memorial")
```

```{r weekday}
# by weekday
train_data_date %>% 
  mutate(weekday = wday(date, label=TRUE)) %>% 
  ggplot(aes(x = weekday, y = lincoln_memorial_departures)) +
  geom_point(alpha = 0.1) + # clearly people cycle more on Saturdays and Sundays
  geom_smooth()

# farah's code here although similar to first one here?
#hour_data_date %>%
  #mutate(weekday = wday(date, label=TRUE)) %>%
  #ggplot(aes(x = weekday, y = lincoln_memorial)) +
  #geom_point(alpha = 0.25) +
  #labs(title = "Capital bikeshare Ridership on Week days") +
  #theme_minimal()
```

```{r day of month}
# by day of the month
train_data_date %>% 
  ggplot(aes(x = day, y = lincoln_memorial_departures)) +
  geom_point(alpha = 0.1, color = "salmon") + # there is no clear pattern across days of the month - aka probably not a good predictor
  geom_smooth()
```

```{r hour}
# by hour
train_data_date %>%
  ggplot(aes(x = hour, y = lincoln_memorial_departures)) +
  geom_col(alpha = 0.1, color = "lightblue") + # people cycle more in the middle of the day, like between 1 and 7PM
  geom_smooth()
```

```{r hour & month}
# by hour & month
train_data_date %>%
  ggplot(aes(x = hour, y = lincoln_memorial_departures)) +
  geom_point(alpha = 0.1, color = "dark green") + # people cycle more in the middle of the day, like between 1 and 7PM
  geom_smooth() +
  facet_wrap(~month)
```


```{r month}
# by month
train_data_date %>% 
  ggplot(aes(x = month, y = lincoln_memorial_departures)) +
  geom_point(alpha = 0.1, color="dark red") + 
  # people cycle most in Spring, summer and fall. Surprised that there is no big spike in summer months
  geom_smooth()
```


```{r year}

# by year
train_data_date %>% 
  # something is off with the year variable, how can we remove the space in the middle? #add factor()
  ggplot(aes(x = factor(year), y = lincoln_memorial_departures)) +
  geom_col(width = 0.5, color = "salmon") + 
  # overall, more people use the service in 2021 than in 2020
  geom_smooth()
```

```{r specific day}
# for a specific month and day, seeing variance by hour
train_data_date %>% 
  filter(year == 2021, month == "Aug", day == 15) %>% 
  ggplot(aes(x= hour, y = lincoln_memorial_departures)) +
  geom_line(color = "Red")
```

```{r holidays}

# prep training data for holiday barchart - 1 year of data from May 2020 to April 2021
# bar_date <- train_data_date %>%
#   filter(year==2020 | year==2021 & month== "Jan" | year==2021 & month== "Feb"|year==2021 & month== "Mar"|year==2021 & month== "Apr") %>%
#   group_by(day, month, year)%>%
#   summarise(lincoln_memorial_departures=sum(lincoln_memorial_departures), n())

bar_date <- train_data_date %>%
  filter(year==2021 & month== "Jan" & day=="1") %>%
  group_by(day, month, year)%>%
  summarise(lincoln_memorial_departures=sum(lincoln_memorial_departures), n())


## confirmed: 365 days exist in this data frame
# check for missingness 
sum(is.na(bar_date$lincoln_memorial_departures)) #0

# what is the mean ridership per day
mean_day <- bar_date %>%
  group_by(day) %>%
  summarize(n= mean(lincoln_memorial_departures)) %>%
  summarize(mean(n))  ## mean per day is 1279
              
# create a dataframe for holidays
holidays <- generated_holidays %>%
  filter(country=="US") 

holidays$ds <- as_date(ymd(holidays$ds)) 

holidays <- holidays %>%
  mutate(
    day=day(ymd(ds)),
    month=month(ymd(ds), label = TRUE)
                     ) %>%
  filter(year==2020 | year==2021) 

holidays_date <- left_join(bar_date, holidays, by= c('year', 'month', 'day')) %>%
    na.omit(holidays) 

holidays_date %>%
  ggplot(aes(y= holiday, x= lincoln_memorial_departures , fill=lincoln_memorial_departures)) + 
  geom_col()+
  geom_vline(xintercept = 1279, color="blue")+ ## 1279 is the mean ridership per day
  xlab("") +
  ylab("Number of departures") +
  scale_colour_discrete("Holidays")+
  labs(title = "", caption = "") +
  guides(fill=guide_legend(title="Number of departures")) +
  theme_minimal() +
  theme(plot.caption = element_text(face = "italic")
  ) 


 ggsave("holidaybar.jpg", width = 50, height = 20, units = "cm")


```

```

## Heat maps
```{r heat}

# The below data can be used for a heat map - not sure what we want to show though?
# Why only a very small area is shown in the map?

# coord_data <- data %>% 
#   select(station, lat, lng) %>% 
#   filter(duplicated(station) == FALSE)
# 
# heat_map_data <- data %>% 
#   # filter() %>% Filter here if you want a certain date range
#   group_by(station, type) %>% 
#   summarize(count = n()) %>% 
#   pivot_wider(names_from = type, values_from = count) %>% 
#   left_join(coord_data) %>% 
#   filter(!is.na(lat), !is.na(lng))
# 
# library(sf)
# library(tigris)
# 
# states <- tigris::states(cb = TRUE, progress_bar = FALSE) %>% 
#     st_crop(xmin = -77.4, xmax = -76.8,
#     ymin = 38.75, ymax = 39.15)
# 
# dep_sf <- heat_map_data %>% 
#   st_as_sf(coords=c("lng", "lat"), remove = FALSE) %>% 
#   st_set_crs(value = 4326)
# 
# dep_sf %>% 
#   ggplot() + 
#   geom_sf(data = states, fill = NA ) +
#   geom_sf(aes(color = departure), alpha = 0.3)
# 
# dep_sf %>% 
#   ggplot() + 
#   geom_sf(data = states, fill = NA ) +
#   geom_sf(aes(color = arrival), alpha = 0.3)
# 
# dep_sf %>% 
#   ggplot() + 
#   geom_sf(data = states, fill = NA ) +
#   geom_sf(aes(color = departure - arrival), alpha = 0.3)

```


## Visualizations by weather at Lincoln Memorial

```{r temperatures}
# weather viz
train_data_date %>%
  ggplot(aes(x = temperature, y = lincoln_memorial_departures))+
  geom_point(alpha = 0.07,color = 'orange')+
  labs(x ='Temperature', y = 'Hourly Departures and Arrivals')+
  geom_smooth() # as the temperature goes up, departures and arrivals go up
```

```{r temperatures_month}
# temperature in each month
train_data_date %>%
  ggplot(aes(x = temperature, y = lincoln_memorial_departures))+
  geom_point(alpha = 0.07, color = 'orange') +
  labs(x= 'Temperature', y = 'Hourly Departures and Arrivals')+
  geom_smooth() + #super confused as to why November and December have hot temperature?
  facet_wrap(~month)
```



```{r wind}
# wind viz
train_data_date %>%
  ggplot(aes(x = wind_speed,y = lincoln_memorial_departures))+
  geom_point(alpha = 0.1,color = 'blue')+
  labs(x = 'Wind Speed', y = 'Hourly Departures and Arrivals') +
  geom_smooth() # data is sparse hence why we get this weird trend
```

```{r rain}
# rain viz
train_data_date %>%
  filter(precipitation != 0) %>% 
  #removing 0 to better show relationship
  ggplot(aes(x = precipitation,y = lincoln_memorial_departures))+
  geom_point(alpha = 0.1,color = 'blue')+
  labs(x = 'Precipitation', y = 'Hourly Departures and Arrivals') +
  geom_smooth()
# Negative relationship between bike usage and precipitation as expected
# data very sparse hence why weird trend. Aaron recommended also creating a variable that dychotomizes rain. 1 if it rains 0 if it doesn't.
```


```{r clouds}
#cloud viz
train_data_date %>%
  ggplot(aes(x = cloud_cover,y = lincoln_memorial_departures))+
  geom_point(alpha = 0.07,color = 'blue')+
  labs(x = 'Cloud Cover', y = 'Hourly Departures and Arrivals') +
  geom_smooth()
# not sure why the data looks like this?
```


```{r heatmap}


heatmap <- train_data_date %>%
  select (hour, lincoln_memorial_departures)  %>%
    group_by (hour) %>%
  summarize (sum_rider =sum(lincoln_memorial_departures))

data_melt <- melt(heatmap, id= "hour")
  

data_melt %>%
 ggplot( aes(hour, variable)) +
    geom_tile(aes(fill = value)) +
    labs(x = NULL,
         y = NULL) + 
  scale_fill_gradientn(colors = "blue") +
   # scale_fill_gradientn(colours = rainbow(10)) +
 # scale_fill_gradient(low = "white", mid = "blue", high = "black")+
  scale_fill_gradient(low = "#FFFFFFFF",
                    high = "#012345")  +
    theme(legend.position = "right",
          legend.direction = "vertical",
          axis.line.x = element_blank(),
          panel.grid.major.y = element_blank()) 



```

