---
title: "visualizations"
author: "Capital Bikes Team"
date: "11/13/2021"
output: html_document
---

```{r include = FALSE}
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::opts_chunk$set(cache = FALSE)
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(options$size != "normalsize", paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
  }
)
# knitr::knit_hooks$set(inline = function(x) {
#   prettyNum(round(x, 2), big.mark = ",")
# })
options(scipen=999)
```


\begin{center}
\Huge{PPOL 670 | Final Project}

\Huge{Visualizations}
\end{center}

\vspace{0.1in}

[GitHub](https://github.com/elenabagnera/CapitalBikesProject)

## Setup
```{r setup, message=FALSE}
library(tidyverse)
library(httr)
library(jsonlite)
source("times.R")
source("io.R")
source("manipulate_data.R")
library(tidymodels)
```


[Direct link to dataset](https://s3.amazonaws.com/capitalbikeshare-data/202108-capitalbikeshare-tripdata.zip)


```{r get_data, cache = FALSE, warning = FALSE, message = FALSE}

### get real-time data through API
url <- "https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/Transportation_WebMercator/MapServer/5/query?where=1%3D1&outFields=*&outSR=4326&f=json"

# 1) use the URL to make a request from the API
data_json <- GET(url = url,
                 user_agent("Georgetown University Assignment"))
# 2) Check for a server error in the response
http_status(data_json)
# 3) get the contents of the response as a text string
data_json <- content(data_json, as = "text")
# 4) create a character matrix from the JSON
data_matrix <- fromJSON(data_json)
# 5) turn the body of the character matrix into a tibble
realtime_data <- as_tibble(data_matrix$features$attributes)
#help needed: how to use lower case for var names?

### get historical data through CSVs
cbs_data <- read_files('data/')

data <- sep_departures_from_arrivals(cbs_data) %>%
  filter_by_distance(from_station = 'lincoln_memorial', distance_m = 1600) # added filtering

hour_data <- get_station_hourly(data) %>% 
  get_historic_weather() # added weather


# The grouped data does not have the original date column, but it can be nice
#  for visualizations. There is a function to do this in times.R
hour_date_date <- add_date_column(hour_data)

```

## Splitting training vs testing data


```{r split}
set.seed(28021995)

# create a split object
data_split <- initial_split(hour_data_date, prop = 0.8)

# create the training and testing data
train_date_date <- training(x = data_split)
test_date_date  <- testing(x = data_split)
```

## Summary stats

```{r stats_dependent}

train_date_date%>%
  summarize(mean(lincoln_memorial), max(lincoln_memorial), min(lincoln_memorial), sd(lincoln_memorial)) # how can we get better sumamry stats? maybe not split by hour?

```


```{r stats_weather}

train_date_date %>%
 # mutate(weekday = wday(date, label=TRUE)) %>%
  group_by(month) %>%
  summarize(mean(temperature), max(temperature), min(temperature), sd(temperature)) 

```

## Visualizations by time at Lincoln Memorial

Amount of rides at the Lincoln memorial over all the time, and by various metrics

```{r visualizations}

train_date_date %>%  # for me here there is a weird gap after July 2020, not sure why?
  ggplot() +
  geom_point(aes(x = date, y = lincoln_memorial,
                 color = type))
```

```{r weekday}
# by weekday
train_date_date %>% 
  mutate(weekday = wday(date, label=TRUE)) %>% 
  ggplot() +
  geom_point(aes(x = weekday, y = lincoln_memorial,
                 color=type)) # clearly people cycle more on saturdays and sundays

# farah's code here although similar to first one here?
#hour_data_date %>%
  #mutate(weekday = wday(date, label=TRUE)) %>%
  #ggplot(aes(x = weekday, y = lincoln_memorial)) +
  #geom_point(alpha = 0.25) +
  #labs(title = "Capital bikeshare Ridership on Week days") +
  #theme_minimal()


```

```{r dayofmonth}
# by day of the month
train_date_date %>% 
  ggplot() +
  geom_point(aes(x = day, y = lincoln_memorial,
                 color=type)) # there is no clear pattern across days of the month - aka probably not a good predictor

```

```{r hour}

# by hour
train_date_date %>% 
  ggplot() +
  geom_point(aes(x = hour, y = lincoln_memorial,
                 color=type)) # people cycle more in the middle of the day, like between 1 and 7PM

```

```{r month}

train_date_date %>% 
  ggplot() +
  geom_point(aes(x = month, y = lincoln_memorial,
                 color=type)) # people cycle most in Spring, summer and fall. Suprised that there is no big spike in summer months

```


```{r year}

train_date_date %>% # something is off with the year variable
  ggplot() +
  geom_point(aes(x = year, y = lincoln_memorial,
                 color=type)) # overall, more people use the service in 2021 than in 2020

```

```{r specific day}

# for a specific month and day, seeing variance by hour
train_date_date %>% 
  filter(year == 2021, month == "Aug", day == 15) %>% 
  ggplot() +
  geom_line(aes(x  =hour, y = lincoln_memorial,
                color=type))

```

## Heat maps

```{r heat}
# The below data can be used for a heat map.
coord_data <- data %>% 
  select(station, lat, lng) %>% 
  filter(duplicated(station) == FALSE)

heat_map_data <- data %>% 
  # filter() %>% Filter here if you want a certain date range
  group_by(station, type) %>% 
  summarize(count = n()) %>% 
  pivot_wider(names_from = type, values_from = count) %>% 
  left_join(coord_data) %>% 
  filter(!is.na(lat), !is.na(lng))
  

library(sf)
library(tigris)

states <- tigris::states(cb = TRUE, progress_bar = FALSE) %>% 
    st_crop(xmin = -77.4, xmax = -76.8,
    ymin = 38.75, ymax = 39.15)

dep_sf <- heat_map_data %>% 
  st_as_sf(coords=c("lng", "lat"), remove = FALSE) %>% 
  st_set_crs(value = 4326)

dep_sf %>% 
  ggplot() + 
  geom_sf(data = states, fill = NA ) +
  geom_sf(aes(color = departure), alpha = 0.3)

dep_sf %>% 
  ggplot() + 
  geom_sf(data = states, fill = NA ) +
  geom_sf(aes(color = arrival), alpha = 0.3)

dep_sf %>% 
  ggplot() + 
  geom_sf(data = states, fill = NA ) +
  geom_sf(aes(color = departure - arrival), alpha = 0.3)
```


## Visualizations by weather at Lincoln Memorial

```{r temperatures}

train_date_date %>%
  ggplot(aes(x=temperature,y=lincoln_memorial))+
  geom_point(alpha=0.07,color='orange')+
  labs(x='Temperature', y= 'Hourly Departures and Arrivals')+
  geom_smooth(method='lm',color= 'red') # as the temperature goes up, departures and arrivals go up

```

```{r wind}

train_date_date %>%
  ggplot(aes(x=wind_speed,y=lincoln_memorial))+
  geom_point(alpha=0.07,color='blue')+
  labs(x='Wind Speed', y= 'Hourly Departures and Arrivals') 
  #geom_smooth(method='lm',color= 'red') # when I add this I get an upward trend, which is weird since it's a negative relationship?


# also notice that there is missing data

```

```{r rain}

train_date_date %>%
  ggplot(aes(x=precipitation,y=lincoln_memorial))+
  geom_point(alpha=0.07,color='blue')+
  labs(x='Precipiation', y= 'Hourly Departures and Arrivals') +
  geom_smooth(method='lm',color= 'red') # Negative relationship between bike usage and precipitation as expected

# definitely need to do some transformations to the rain variable as there doesn't seem to be a lot of variation?

```


```{r clouds}

train_date_date %>%
  ggplot(aes(x=cloud_cover,y=lincoln_memorial))+
  geom_point(alpha=0.07,color='blue')+
  labs(x='Cloud Cover', y= 'Hourly Departures and Arrivals') 

# doesn't seem like a good predictor?

```